{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nagarjuna741621/ML/blob/main/Naive_Bayes_AP23110011370.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LUX0LaYmKNa"
      },
      "source": [
        "# TASK #1: UNDERSTAND THE PROBLEM AND BUSINESS CASE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3v1qT0AtBiw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbBapz4HBR7D"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25EaFC1BBR7F"
      },
      "outputs": [],
      "source": [
        "# Data Source: https://www.kaggle.com/samdeeplearning/deepnlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5EUjR4ZBR7H"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VulXquoOxhD"
      },
      "source": [
        "# TASK #2: IMPORT LIBRARIES AND DATASETS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phlUGBnOBR7I"
      },
      "outputs": [],
      "source": [
        "# install nltk\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdUUo09eBR7K"
      },
      "outputs": [],
      "source": [
        "# install gensim\n",
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jupyterthemes"
      ],
      "metadata": {
        "id": "9nCo0XXWCHfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kvy7-kXoBR7L"
      },
      "outputs": [],
      "source": [
        "!pip install wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpiddPjsl_4Q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Fjta7rpBR7M"
      },
      "outputs": [],
      "source": [
        "from jupyterthemes import jtplot\n",
        "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)\n",
        "# setting the style of the notebook to be monokai theme\n",
        "# this line of code is important to ensure that we are able to see the x and y axes clearly\n",
        "# If you don't run this code line, you will notice that the xlabel and ylabel on any plot is black on black and it will be hard to see them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QiTczEunJNx",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# load the data\n",
        "resume_df = pd.read_csv('resume.csv',encoding = 'latin-1')\n",
        "resume_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DB2gQ1w4nR-P",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# data containing resume\n",
        "resume_df = resume_df[['resume_text','class']]\n",
        "resume_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCNfxoREBR7P"
      },
      "source": [
        "MINI CHALLENGE #1:\n",
        "- Print the first and last elements in the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DaYnKlaBR7P"
      },
      "outputs": [],
      "source": [
        "print(resume_df.head(10))\n",
        "print(resume_df.tail(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBqxz1TBPBLE"
      },
      "source": [
        "# TASK #3: PERFORM EXPLORATORY DATA ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZZjlzQenXRI"
      },
      "outputs": [],
      "source": [
        "# obtain dataframe information\n",
        "resume_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9adoDKHopVq"
      },
      "outputs": [],
      "source": [
        "# check for null values\n",
        "resume_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ak3V9F87keK"
      },
      "outputs": [],
      "source": [
        "resume_df['class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMHJFK-r6-sP",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "resume_df['class'] = resume_df['class'].apply(lambda x:0 if x == 'not_flagged' else 1)\n",
        "resume_df['class'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmPv-hJGBR7S"
      },
      "source": [
        "MINI CHALLENGE #2:\n",
        "- Divide the DataFrame into two, one that belongs to class 0 and 1. Do we have a balanced dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "NCbKGE4zBR7S"
      },
      "outputs": [],
      "source": [
        "class_0_df = resume_df[resume_df['class'] == 0]\n",
        "class_0_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nMNoc7YBR7T"
      },
      "outputs": [],
      "source": [
        "class_1_df = resume_df[resume_df['class'] == 1]\n",
        "class_1_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgkZHO3CPnsp"
      },
      "source": [
        "# TASK #4: PERFORM DATA CLEANING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh7Cq-5lAwol"
      },
      "outputs": [],
      "source": [
        "resume_df['resume_text'] = resume_df['resume_text'].apply(lambda x: x.replace('\\r',''))\n",
        "resume_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51VMI7E2ODX8"
      },
      "outputs": [],
      "source": [
        "# download nltk packages\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDtZAF0l8qx4"
      },
      "outputs": [],
      "source": [
        "# download nltk packages\n",
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlZjHcAb8t91",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Get additional stopwords from nltk\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from','subject','re','use','email','com'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Sl0PEtkKhfn"
      },
      "outputs": [],
      "source": [
        "# Remove stop words and remove words with 2 or less characters\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text) :\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2 and token not in stop_words:\n",
        "            result.append(token)\n",
        "\n",
        "    return ' '.join(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xhh3-a4tRgIR"
      },
      "outputs": [],
      "source": [
        "# Cleaned text\n",
        "resume_df['cleaned'] = resume_df['resume_text'].apply(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuia_epuBR7V"
      },
      "outputs": [],
      "source": [
        "resume_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUpOyCcIBR7W"
      },
      "outputs": [],
      "source": [
        "print(resume_df['cleaned'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2fyiTSEFvfK"
      },
      "outputs": [],
      "source": [
        "print(resume_df['resume_text'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf4bOLzfPc78"
      },
      "source": [
        "# TASK #5: VISUALIZE CLEANED DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXoj-rLAGGpn",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Plot the counts of flagged vs not flagged\n",
        "sns.countplot(x=resume_df['class'], label = 'Count Plot')\n",
        "plt.title('Distribution of Resume Classes')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTUOMF5nUnbC"
      },
      "outputs": [],
      "source": [
        "# plot the word cloud for text that is flagged\n",
        "plt.figure(figsize = (20,20))\n",
        "wc = WordCloud(max_words = 2000 , width = 1600 , height = 800 , stopwords = stop_words).generate(str(resume_df[resume_df['class'] == 1].cleaned))\n",
        "plt.imshow(wc , interpolation = 'bilinear')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECeAOLSiBR7Z"
      },
      "source": [
        "MINI CHALLENGE #3:\n",
        "- Plot the wordcloud for class #1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r20ny06ECP1B"
      },
      "outputs": [],
      "source": [
        "# plot the word cloud for text that is flagged\n",
        "plt.figure(figsize = (20,20))\n",
        "wc = WordCloud(max_words = 2000 , width = 1600 , height = 800 , stopwords = stop_words).generate(str(resume_df[resume_df['class'] == 0].cleaned))\n",
        "plt.imshow(wc , interpolation = 'bilinear')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi3neznbP_QT"
      },
      "source": [
        "# TASK #6: PREPARE THE DATA BY APPLYING COUNT VECTORIZER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXtxHREnBR7Z"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUgEf-SZ7R7c"
      },
      "outputs": [],
      "source": [
        "# CountVectorizer example\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "sample_data = ['Hello World', 'Hello Hello Hello World world', 'Hello Hello World world world World']\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(sample_data)\n",
        "\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCKWdS-oPzhJ"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(resume_df['cleaned'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kme-IYsM6uJa"
      },
      "outputs": [],
      "source": [
        "# Applying CountVectorier to the cleaned text\n",
        "print(vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.toarray())"
      ],
      "metadata": {
        "id": "MN22GbweGedi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuhYli9FQN1Q"
      },
      "source": [
        "# TASK #7: UNDERSTAND THE THEORY AND INTUITION BEHIND NAIVE BAYES CLASSIFIERS - PART #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHUs2tIYBR71"
      },
      "source": [
        "# TASK #8: UNDERSTAND THE THEORY AND INTUITION BEHIND NAIVE BAYES CLASSIFIERS - PART #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9o5TQbnBR71"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4xfo_u6BR72"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPNcs34BR72"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVIehNbkBR73"
      },
      "source": [
        "MINI CHALLENGE #4:\n",
        "- Calculate the probability of the red class (non-retiring)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLlN3dRGBR73"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zYvpYgfV14h"
      },
      "source": [
        "# TASK#9: TRAIN NAIVE BAYES CLASSIFIER MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX2ufUXMZHjC"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr_lGcmdl0Lv"
      },
      "outputs": [],
      "source": [
        "y = resume_df['class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9mSySZLZLNi"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOvBx9AHZMtD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "NB_classifier = MultinomialNB()\n",
        "NB_classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "h-Kki_8dIyZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPTFQxhHUrNv"
      },
      "source": [
        "MINI CHALLENGE #5:\n",
        "- Split the data into 25% testing and 75% training and perform a sanity check\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGWgD1gJBR79"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXa2MqEQQ2ww"
      },
      "source": [
        "# TASK #10: ASSESS TRAINED MODEL PERFORMANCE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA7XyuI2BR79"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qRUkys-BSuQ"
      },
      "outputs": [],
      "source": [
        "# Predicting the performance on train data\n",
        "y_predict_train = NB_classifier.predict(X_train)\n",
        "y_predict_train\n",
        "cm = confusion_matrix(y_train, y_predict_train)\n",
        "sns.heatmap(cm, annot = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qh66RfZgF7ln"
      },
      "outputs": [],
      "source": [
        "# Predicting the Test set results\n",
        "y_predict_test = NB_classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_predict_test)\n",
        "sns.heatmap(cm, annot = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTSddgb6F_o6"
      },
      "outputs": [],
      "source": [
        "# classification report\n",
        "print(classification_report(y_test, y_predict_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZrxEDyLBR7_"
      },
      "source": [
        "MINI CHALLENGE #6:\n",
        "- Retrain the model after spliting the data into 30% testing and 70% training and assess model performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVLO63jBBR7_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
        "\n",
        "NB_classifier = MultinomialNB()\n",
        "NB_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_predict_test = NB_classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_predict_test)\n",
        "sns.heatmap(cm, annot = True)\n",
        "\n",
        "# classification report\n",
        "print(classification_report(y_test, y_predict_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA0evED8Q983"
      },
      "source": [
        "# GREAT JOB!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsFJM1gcBR8A"
      },
      "source": [
        "# MINI CHALLENGES SOLUTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L-ixLabQW-m"
      },
      "source": [
        "MINI CHALLENGE #1 SOLUTION:\n",
        "- Print the first and last elements in the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6kXBsESBR8A"
      },
      "outputs": [],
      "source": [
        "resume_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXUNfFKPBR8B"
      },
      "outputs": [],
      "source": [
        "resume_df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EuA_4KdQXE-"
      },
      "source": [
        "MINI CHALLENGE #2 SOLUTION:\n",
        "- Divide the DataFrame into two, one that belongs to class 0 and 1. Do we have a balanced dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0SUO5E9BR8D"
      },
      "outputs": [],
      "source": [
        "class_0_df = resume_df[resume_df['class']==0]\n",
        "class_0_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2bqcsmJBR8D"
      },
      "outputs": [],
      "source": [
        "class_1_df = resume_df[resume_df['class']==1]\n",
        "class_1_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x762n3wbBR8E"
      },
      "source": [
        "MINI CHALLENGE #3 SOLUTION:\n",
        "- Plot the wordcloud for class #1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6_l9yklBR8E"
      },
      "outputs": [],
      "source": [
        "# plot the word cloud for text that is not flagged\n",
        "plt.figure(figsize = (20, 20))\n",
        "wc = WordCloud(max_words = 2000 , width = 1600 , height = 800 , stopwords = stop_words).generate(str(resume_df[resume_df['class'] == 0].cleaned))\n",
        "plt.imshow(wc , interpolation = 'bilinear')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVeweCVGBR8E"
      },
      "source": [
        "MINI CHALLENGE #4 SOLUTION:\n",
        "- Calculate the probability of the red class (non-retiring)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90Yjb7OiBR8F"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnrFPKAyBR8F"
      },
      "source": [
        "MINI CHALLENGE #5 SOLUTION:\n",
        "- Split the data into 25% testing and 75% training and perform a sanity check\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IYfiG24BR8F"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyuyffTDUoL8"
      },
      "source": [
        "MINI CHALLENGE #6 SOLUTION:\n",
        "- Retrain the model after spliting the data into 30% testing and 70% training and assess model performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2-Q1ORmBR8G"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
        "\n",
        "NB_classifier = MultinomialNB()\n",
        "NB_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_predict_test = NB_classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_predict_test)\n",
        "sns.heatmap(cm, annot = True)\n",
        "\n",
        "# classification report\n",
        "print(classification_report(y_test, y_predict_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s58kPyzzBR8G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hd5xaYvuBR8G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tii3BPa1BR8G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gRd15xVBR8G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}